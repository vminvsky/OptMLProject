
Epoch: 0, Loss:  0.6889362931251526
Epoch: 0, Loss:  0.6822221279144287
Epoch: 0, Loss:  0.6830028295516968
Epoch: 0, Loss:  0.677329421043396
Epoch: 0, Loss:  0.6822285652160645
Epoch: 0, Loss:  0.6730009913444519
Epoch: 0, Loss:  0.6888505220413208
Epoch: 0, Loss:  0.6812264919281006
Epoch: 0, Loss:  0.6794219017028809
Epoch: 0, Loss:  0.6889036893844604
Epoch: 0, Loss:  0.6655769348144531
Epoch: 0, Loss:  0.6643581390380859
Epoch: 0, Loss:  0.6835500001907349
Epoch: 0, Loss:  0.6690829992294312
Epoch: 0, Loss:  0.6775217056274414
Epoch: 0, Loss:  0.6800554990768433
Epoch: 0, Loss:  0.6742823123931885
Epoch: 0, Loss:  0.6752771735191345
Epoch: 0, Loss:  0.6713312864303589
Epoch: 0, Loss:  0.6820051670074463
Epoch: 0, Loss:  0.6776646375656128
Epoch: 0, Loss:  0.6771513223648071
Epoch: 0, Loss:  0.6676249504089355
Epoch: 0, Loss:  0.6816242933273315
Epoch: 0, Loss:  0.6753332614898682
Epoch: 0, Loss:  0.6861501932144165
Epoch: 0, Loss:  0.6631657481193542
Epoch: 0, Loss:  0.67039954662323
Epoch: 0, Loss:  0.6739834547042847
Epoch: 0, Loss:  0.6682846546173096
Epoch: 0, Loss:  0.677368700504303
Epoch: 0, Loss:  0.6669634580612183
Epoch: 0, Loss:  0.6757450699806213
Epoch: 0, Loss:  0.6860312223434448
Epoch: 0, Loss:  0.6848005056381226
Epoch: 0, Loss:  0.6774806380271912
Epoch: 0, Loss:  0.6573954820632935
Epoch: 0, Loss:  0.7014945149421692
Traceback (most recent call last):
  File "/scratch/venia/OptMLProject/finetuning/finetuning.py", line 250, in <module>
    main()  # pragma: no cover
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/scratch/venia/OptMLProject/finetuning/finetuning.py", line 211, in main
    optimizer.step(closure)
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/venia/OptMLProject/finetuning/optimizers/sam.py", line 46, in step
    closure()
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/venia/OptMLProject/finetuning/finetuning.py", line 207, in closure
    loss.backward()
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt