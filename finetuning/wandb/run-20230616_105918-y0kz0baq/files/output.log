2000
Epoch: 0, Loss:  0.6889362931251526
Epoch: 0, Loss:  0.638645589351654
Epoch: 0, Loss:  0.666481077671051
Epoch: 0, Loss:  0.4962145686149597
Epoch: 0, Loss:  0.5752992630004883
Epoch: 0, Loss:  0.4455890655517578
Epoch: 0, Loss:  0.8596620559692383
Epoch: 0, Loss:  0.4870849549770355
Epoch: 0, Loss:  0.6391502022743225
Epoch: 0, Loss:  0.6717795133590698
Epoch: 0, Loss:  0.48227667808532715
Epoch: 0, Loss:  0.5581018924713135
Epoch: 0, Loss:  0.6593953967094421
Epoch: 0, Loss:  0.5058677792549133
Epoch: 0, Loss:  0.6559401750564575
Epoch: 0, Loss:  0.6031637191772461
Epoch: 0, Loss:  0.4537256956100464
Epoch: 0, Loss:  0.5732817053794861
Epoch: 0, Loss:  0.6305153369903564
Epoch: 0, Loss:  0.566236138343811
Epoch: 0, Loss:  0.5703431963920593
Epoch: 0, Loss:  0.4573267698287964
Epoch: 0, Loss:  0.6503248810768127
Epoch: 0, Loss:  0.5638677477836609
Epoch: 0, Loss:  0.5164911150932312
Epoch: 0, Loss:  0.5681486129760742
Epoch: 0, Loss:  0.5190064907073975
Epoch: 0, Loss:  0.45321258902549744
Epoch: 0, Loss:  0.648529052734375
Epoch: 0, Loss:  0.5549900531768799
Epoch: 0, Loss:  0.7276000380516052
Epoch: 0, Loss:  0.4938894510269165
Epoch: 0, Loss:  0.532768964767456
Epoch: 0, Loss:  0.6271558403968811
Epoch: 0, Loss:  0.5570746660232544
Epoch: 0, Loss:  0.4864717721939087
Epoch: 0, Loss:  0.45029187202453613
Traceback (most recent call last):
  File "/scratch/venia/OptMLProject/finetuning/finetuning.py", line 255, in <module>
    main()  # pragma: no cover
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/scratch/venia/OptMLProject/finetuning/finetuning.py", line 216, in main
    optimizer.step(closure)
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/venia/OptMLProject/finetuning/optimizers/sam.py", line 46, in step
    closure()
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/venia/OptMLProject/finetuning/finetuning.py", line 212, in closure
    loss.backward()
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt