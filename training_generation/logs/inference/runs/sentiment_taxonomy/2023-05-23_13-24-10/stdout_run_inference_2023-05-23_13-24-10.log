[2023-05-23 13:24:10,660][__main__][INFO] - Generating data using 20 threads across 2 keys.
[2023-05-23 13:24:10,660][__main__][INFO] - Dataset is 500 rows
[2023-05-23 13:24:11,562][openai][INFO] - error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16083c1be0006ed17b1cd562423b97a5 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:24:11,562][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16083c1be0006ed17b1cd562423b97a5 in your message.) {
  "error": {
    "message": "The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16083c1be0006ed17b1cd562423b97a5 in your message.)",
    "type": "server_error",
    "param": null,
    "code": null
  }
}
 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16083c1be0006ed17b1cd562423b97a5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 11:24:11 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '121', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3497', 'x-ratelimit-remaining-tokens': '80015', 'x-ratelimit-reset-requests': '35ms', 'x-ratelimit-reset-tokens': '6.656s', 'x-request-id': '16083c1be0006ed17b1cd562423b97a5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbcee58b9bb3b52-GVA', 'alt-svc': 'h3=":443"; ma=86400, h3-29=":443"; ma=86400'}.
[2023-05-23 13:24:11,610][openai][INFO] - error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b94556ee5ecd3cb776b0871154a7331c in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:24:11,610][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b94556ee5ecd3cb776b0871154a7331c in your message.) {
  "error": {
    "message": "The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b94556ee5ecd3cb776b0871154a7331c in your message.)",
    "type": "server_error",
    "param": null,
    "code": null
  }
}
 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b94556ee5ecd3cb776b0871154a7331c in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 11:24:11 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '134', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3498', 'x-ratelimit-remaining-tokens': '68411', 'x-ratelimit-reset-requests': '32ms', 'x-ratelimit-reset-tokens': '14.392s', 'x-request-id': 'b94556ee5ecd3cb776b0871154a7331c', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbcee590a013b58-GVA', 'alt-svc': 'h3=":443"; ma=86400, h3-29=":443"; ma=86400'}.
[2023-05-23 13:24:41,123][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f1629cf45d900d7f6d690ad72a82cbc in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:24:41,124][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f1629cf45d900d7f6d690ad72a82cbc in your message.).
[2023-05-23 13:24:41,541][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ce8f093ef109879c5f43a6a8025eea7 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:24:41,542][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ce8f093ef109879c5f43a6a8025eea7 in your message.).
[2023-05-23 13:25:10,878][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:10,898][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:10,910][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:10,939][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:10,980][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:11,032][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:11,038][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:11,106][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:11,111][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:15,741][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 859f47e4ba1240fc952f1e1adf05023a in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:25:15,742][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 859f47e4ba1240fc952f1e1adf05023a in your message.).
[2023-05-23 13:25:32,318][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 817b3889809fbccc24e8c6f872c65638 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:25:32,319][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 817b3889809fbccc24e8c6f872c65638 in your message.).
[2023-05-23 13:25:46,712][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:53,106][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:53,735][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:54,638][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7265d1e8f2fa32955bb5ad1cd8464bab in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:25:54,639][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7265d1e8f2fa32955bb5ad1cd8464bab in your message.).
[2023-05-23 13:25:57,313][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:25:59,037][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:04,630][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:05,191][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:11,985][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:11,985][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:12,022][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:12,069][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:12,122][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:12,138][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:23,716][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:26,855][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:46,046][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13de4bdfc576d3b4d80e464ac7b4974d in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:26:46,047][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13de4bdfc576d3b4d80e464ac7b4974d in your message.).
[2023-05-23 13:26:54,193][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:55,979][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:26:58,102][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de8d56a51dd2d2e08efd1fc85ad7a1b9 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:26:58,102][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de8d56a51dd2d2e08efd1fc85ad7a1b9 in your message.).
[2023-05-23 13:27:02,175][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d15571b3eb6f9571b7a143fa77d80721 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:27:02,176][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d15571b3eb6f9571b7a143fa77d80721 in your message.).
[2023-05-23 13:27:04,270][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b1b15bea80343011c7427b5e7b6b57f in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:27:04,271][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b1b15bea80343011c7427b5e7b6b57f in your message.).
[2023-05-23 13:27:05,936][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:27:14,082][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:27:14,118][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:27:24,798][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:27:56,074][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:28:00,184][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:28:18,186][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:28:26,842][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:28:34,418][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bbeaaa8c8283012fb600119ccd93e506 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-05-23 13:28:34,418][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bbeaaa8c8283012fb600119ccd93e506 in your message.).
[2023-05-23 13:28:38,285][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:28:55,190][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:28:59,226][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:29:26,286][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:29:30,927][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:29:39,336][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:29:42,490][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:29:46,963][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:30:41,422][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:31:35,165][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:31:45,469][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:32:36,250][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:32:53,574][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:34:09,684][__main__][ERROR] - OpenAI request timed out. Skipping this entry.
[2023-05-23 13:35:09,902][langchain.chat_models.openai][WARNING] - Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).
[2023-05-23 13:36:03,030][__main__][INFO] - Execution time: 712 (s)
