/scratch/venia/python/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                                                                                   | 0/576 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '







































 33%|████████████████████████████████████████████████████████▎                                                                                                                | 192/576 [01:19<02:26,  2.61it/s]

 33%|████████████████████████████████████████████████████████▎                                                                                                                | 192/576 [01:21<02:26,  2.61it/s]
 33%|████████████████████████████████████████████████████████▎                                                                                                                | 192/576 [01:21<02:26,  2.61it/s]/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '






































 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 384/576 [02:44<01:12,  2.66it/s]

 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 384/576 [02:46<01:12,  2.66it/s]
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 384/576 [02:46<01:12,  2.66it/s]/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 576/576 [04:06<00:00,  2.73it/s]
  0%|                                                                                                                                                                                    | 0/13 [00:00<?, ?it/s]

{'loss': 0.0099, 'learning_rate': 0.0, 'epoch': 3.0}

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 576/576 [04:10<00:00,  2.30it/s]
{'train_runtime': 250.3057, 'train_samples_per_second': 9.181, 'train_steps_per_second': 2.301, 'train_loss': 0.09833846965597735, 'epoch': 3.0}
/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  7.41it/s]
/scratch/venia/python/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 0.31326168751822286, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 1.9051, 'eval_samples_per_second': 26.245, 'eval_steps_per_second': 6.824, 'epoch': 3.0}

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  6.86it/s]
/scratch/venia/socialgpt/venia_worker_vs_gpt/src/finetuning/trainers.py:202: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  probs = softmax(torch.Tensor(y_pred_logits)).numpy()